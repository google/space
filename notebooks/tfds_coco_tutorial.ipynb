{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and manage TFDS COCO Datasets\n",
    "\n",
    "[TFDS COCO dataset](https://www.tensorflow.org/datasets/catalog/coco) defines the following features structure for data serialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow_datasets import features as f\n",
    "\n",
    "tf_features_dict = f.FeaturesDict({\n",
    " \"image\": f.Image(shape=(None, None, 3), dtype=np.uint8),\n",
    " \"objects\": f.Sequence({\n",
    "   \"area\": np.int64,\n",
    "   \"bbox\": f.BBoxFeature(),\n",
    "   \"id\": np.int64,\n",
    "   \"is_crowd\": np.bool,\n",
    "   \"label\": f.ClassLabel(num_classes=80),\n",
    "  }),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example creates a Space dataset for COCO, and copy the `objects` feature to columnar format for analysis. The Space dataset\"s schema is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "from space import TfFeatures\n",
    "\n",
    "object_schema = pa.struct([\n",
    "  (\"area\", pa.int64()),\n",
    "  (\"bbox\", pa.list_(pa.float32())),  # TODO: to use fixed size list.\n",
    "  (\"id\", pa.int64()),\n",
    "  (\"is_crowd\", pa.bool_()),\n",
    "  (\"label\", pa.int64()),\n",
    "])\n",
    "\n",
    "ds_schema = pa.schema([\n",
    "  (\"id\", pa.int64()),\n",
    "  (\"filename\", pa.string()),\n",
    "  (\"objects\", pa.list_(object_schema)),\n",
    "  (\"features\", TfFeatures(tf_features_dict))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new Space dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.create(\"/path/to/space/<mybucket>/demo\",\n",
    "                    ds_schema, primary_keys=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load TFDS\"s ArrayRecord files into Space  without file copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_fn(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "  example = example[\"features\"][0]\n",
    "  return {\n",
    "    \"id\": example[\"image/id\"],\n",
    "    \"filename\": example[\"image/filename\"],\n",
    "    \"objects\": coco_utils.tf_objects_to_pylist(example[\"objects\"]),\n",
    "  }\n",
    "\n",
    "runner = ds.local()\n",
    "runner.load_array_record(\"/path/to/tfds/coco/files\", index_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `objects` field in TFDS becomes a columnar field that can be analyzed via SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Load the \"objects\" column into memory as PyArrow and query using DuckDB.\n",
    "objects = runner.read_all(fields=[\"objects\"])\n",
    "duckdb.sql(\n",
    "  \"SELECT MAX(objs.area) FROM (SELECT unnest(objects) AS objs FROM objects)\"\n",
    ").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space supports data mutations and time travel back to previous versions. No need to rewrite a ML dataset for inserting/deleting/updating data any more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.compute as pc\n",
    "\n",
    "# Delete a row from a Space dataset.\n",
    "# The mutation creates a new snapshot, and set it as the current snapshot.\n",
    "runner.delete(pc.field(\"id\") == pc.scalar(361586))\n",
    "\n",
    "# Time travel back to before the deletion, by setting a read \"snapshot_id\".\n",
    "# Initial snapshot ID is 0, after loading TFDS it becomes 1, after deletion it\n",
    "# is 2.\n",
    "runner.read(snapshot_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Space dataset is also a ML training data source. It is easy to integrate with Jax, Tensorflow, Pytorch, and Ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from space.tf.data_sources import SpaceDataSource\n",
    "\n",
    "# Tensorflow random access interface:\n",
    "# https://www.tensorflow.org/datasets/tfless_tfds\n",
    "# feature_fields defines the feature field to read.\n",
    "tf_ds = SpaceDataSource(ds, feature_fields=[\"features\"])\n",
    "\n",
    "# Returns a Ray dataset.\n",
    "ray_ds = ds.ray_dataset()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
